# AsyncDecodeImage
异步解码大图片帧动画
iOS系统要将图片展示到屏幕上，需要加过图片加载，解码和渲染三个步骤，并且默认会在图片展示时在主线程对图像进行解码。
对于一张m*n像素的BGRA8888（每个像素占四位，即A=8，R=8，G=8，B=8，那么一个像素点占8+8+8+8=32位）PNG图片，其解码后的位图数据大小为m*n*4字节，假设一张500*500的PNG图片，那么其解码后占用的内存将达到1M。
对于需要几十张大图片的帧动画，将会导致内存暴增，并且由于图片解码操作是在主线程进行的，会造成界面卡顿的现象，因此需要解决大图片帧动画的性能问题。

UIKit提供两种常见的图片加载方式：
[UIImage imageNamed:fileName]和[UIImage imageWithContentsOfFile:filePath];

从下图的imageNamed的内部调用堆栈我们可以看到，UIKit的imageNamed是通过ImageIO的CGImageReadCreateWithURL,以mmap内存映射方式从图片路径将图片映射到内存当中，并通过CGImageSourceCreateImageAtIndex创建CGImageRef，并没有涉及到解码的相关函数调用。CGImageRef抽象了图像的基本数据和元数据，并不包含图像真正的位图数据。通过imageNamed创建UIImage时，系统实际上只是在Bundle内查找到文件名，然后把这个文件名放到UIImage里返回，并没有进行实际的文件读取和解码。当UIImage第一次显示到屏幕上，即当UIImageView的image被赋值时，其内部的解码方法才会被调用。同时解码结果会保存到一个全局缓存区，这样在下次展示相同的图片时就不会进行解码操作。对于这个全局缓存我们无法控制，系统只有在内存低时才会将其中的内存释放。UIImage有个CGImage属性，也说明UImage也是CGImageRef在UIKit的一个封装。
 ![image1](https://github.com/Kaibin/AsyncDecodeImage/blob/master/imageNamed.jpg)

同样，imageWithContentsOfFile内部调用如下,也是通过将图片mmap映射到内存然后通过CGImageSourceRef创建CGImageRef。与imageNamed不同的是imageWithContentsOfFile不会对原图做缓存，每次展示图片时都需要解码操作。
 ![image2](https://github.com/Kaibin/AsyncDecodeImage/blob/master/imageWithContentsOfFile.jpg)

UIImageView有一个显示帧动画的属性animationImages，传入一个UIImage的NSArray，设定animationDuration，调用它的startAnimating方法就可以去播放这组图片。但这个方法会一次性加载整个数组的图片，内存消耗太大。不管UIImage是以imageNamed还是imageWithContentsOfFile的形式加载，都会在播放动画过程中解码整个数组图片使得内存暴增。如果使用imageNamed的方式加载图像，由于系统会自动缓存这些图片解码后的数据，这将会很有可能造成内存泄露。

CADisplayLink与屏幕刷新周期完全一致的定时器，可以使用它来实现时钟动画。将CADisplayLink加入到主运行循环队列后，它的时钟周期就和主运行循环保持一致，而主运行循环周期就是屏幕刷新周期。这样我们就可以在每一个时钟周期内通过刷新图片数据来实现逐帧动画，并通过实现每一个时钟周期内对每一只图片进行解码，实现图片边解码边播放。
